# Go言語で学ぶ並行プログラミングの写経

本: [Go言語で学ぶ並行プログラミング　他言語にも適用できる原則とベストプラクティス \- インプレスブックス](https://book.impress.co.jp/books/1123101144)

原著: [Learn Concurrent Programming with Go](https://learning.oreilly.com/library/view/learn-concurrent-programming/9781633438385/)

原著GitHub: [cutajarj/ConcurrentProgrammingWithGo: Listings from manning book](https://github.com/cutajarj/ConcurrentProgrammingWithGo)

## まとめ・感想

### 第1章 並行プログラミング

並行プログラミングの総論的内容。

- Goには並行プログラミングを実現する仕組みとしてゴルーチンがある
- ゴルーチンはCSPという思想の実現化
- CSP方式のモデルを使うことである種の並行プログラミングのエラーを減らせる
- アムダールの法則により実行の非並列部分により水平方向のスケーラビリティに制限がかかることが知られている。
- アムダールの法則への反論としてグスタフンの法則がある

まとめ:

Goの並行性はCSP思想に基づくゴルーチンとチャネルで実現される。CSPは共有メモリの代替でエラー低減に有効。性能はアムダールの法則で制約され、グスタフソンの法則が拡張性の視点を補完する。

感想:

並列、並行プログラミングの問題についての知識があれば斜め読みで良いだろう。

### 第2章 スレッドを扱う

- プロセスの概略
- スレッドの概略
  - OS（カーネルレベル）スレッドとユーザースレッドについての説明
  - ユーザースレッドはユーザー空間で作られ管理されるスレッドのこと
  - カーネルレベルスレッドに比べ軽量でコンテキストスイッチも素早く実行できるが、1つのプロセッサ内でしか動作できないなどの制約がある。
- ゴルーチンについて
  - ゴルーチンの現在の実装は直接OSスレッドには紐付かない
  - ゴルーチンはOSスレッドとユーザースレッドのハイブリッドシステムで実行管理されている
  - ゴルーチンは複数のユーザーレベルスレッドを複数のカーネルレベルスレッドにマッピングされる
  - この仕組みはM:Nスレッディングモデルと言われることがある
  - ゴルーチンはカーネルレベルスレッドの集まりを使い、それぞれがゴルーチンのキューを管理することで実現している。複数のカーネルレベルスレッドがあるので、複数のCPUを使う事ができる
  - GOMAXPROCSという環境変数でGoランタイムが使用するカーネルレベルスレッド数を設定することができ、通常は動作するマシンの論理プロセッサ数代わり当てられる（ch02/03_listing2.4）
  - Goランタイムはカーネルレベルスレッドにローカル実行キュー（LRQ: Local Run Queue）を割り当てる
  - また、Goランタイムはカーネルレベルスレッドに割り当てていないゴルーチンのためにグローバル実行キュー（GRQ: Global Run Queue）を持っている
  - 各カーネルレベルスレッドはLRQに入っているゴルーチンを取り出し実行する
  - あるスレッドでブロッキングが発生しそうになると、Goランタイムは新たなカーネルレベルスレッドを作るか再利用して新たなスレッドに新しいLRQを割り当てる。ブロッキングが発生したスレッドのLRQにいたゴルーチンはこの新しいLRQ
    に移動する。これをワークスティーリングと呼ぶ。
  - ワークスティーリングはブロッキング時だけではなく、キュー内のスレッドの数が不均衡な場合にも行われる
  - GoのスケジューラーがGoルーチンを切り替えるタイミングはユーザーレベルのイベントを必要とする。具体的には新たなゴルーチンの開始、システムコールの実行（たとえばファイル読み込み）、ゴルーチンの同期など
  - コード内でGoスケジューラーを呼び出して、スケジューラーに別のゴルーチンへのコンテキストスイッチをさせるよう試みられる。（ch02/04_listing2.5）
- 並列性と平行性について
  - 平行性: プログラムコードの特性
  - 並列性: 実行プログラムの特性

まとめ:

本章はスレッドとGoのゴルーチン実装を概観する。OSスレッドとユーザースレッドの違いを押さえ、軽量なユーザースレッドの制約も説明。GoのゴルーチンはM:Nモデルで管理され、複数のカーネルスレッド上に多数のゴルーチンをマッピングする。各スレッドはローカル実行キュー（LRQ）を持ち、未割当はグローバル実行キュー（GRQ）で管理。ブロッキングや不均衡時にはワークスティーリングで負荷分散する。GOMAXPROCSで使用する論理プロセッサ数を制御可能。スケジューラーは新規ゴルーチン開始、システムコール、同期などのイベントで切替を行い、明示的に譲歩を試みることもできる。平行性はコードの性質、並列性は実行時の性質として区別する。

感想:

ゴルーチンのスケジューリングに関して理解できて良かった。

### 第3章 メモリ共有を使ったスレッド間通信

- メモリ共有
  - メモリ共有は複数のスレッドで一つの帆ワイドボードを共有するようなもの
  - 実際の計算機でメモリ共有が行われている仕組みについての解説
  - ポインタを使ったゴルーチン間でのメモリ共有（ch03/01_listing3.1）
  - Goのコンパイラはゴルーチン間で共有されているものを発見すると、（一見スタックにあるように見えても）それをスタックではなくヒープに置く
  - `go build -gcflags="-m" countdown.go`こうするとどの変数がヒープに置かれたのかわかる
  - 複数のゴルーチンから単純に同じヒープの値に書き込みを行うと**競合状態**が発生し正しい処理結果を得られない。場合によっては深刻な事態となる
  - 競合状態はプログラムが同時に多くのことを行おうとし、その動作が独立した予測不可能なイベントも関わらず、正確なタイミングで行う必要がある場合に起こる
  - 競合状態はハイゼンバグ（Heisenbug）の良い例。ハイゼンバグは量子力学のハイゼンベルグの不確定性原理から名付けられていて、デバッグして切り分けようとすると消えてしまったり、挙動が変わってしまうバグのこと
  - **アトミック**: 分割できないこと。アトミック操作は分割できない操作のこと
  - **クリティカルセクション**: そのセクションで使われている状態に影響を与える他の実行からの干渉を受けずに実行される命令の集まり
  - - クリティカルセクションの外でGoのスケジューラーを起動しても解決策にはならない（ch03/05_listing3.7）
  - 適切な同期と通信による競合状態の排除
    - 最初のステップはこの問題に対して適切なツールを使っているかの確認。本当にメモリ共有は正しい方法なのか。チャネルとCSPを使う方が適切ではないのか
    - 第2ステップは競合状態がいつ発生するか認識をすること。
  - `go run -race stingyspendysched.go`のように`-race`オプションを就けて実行させることでGoに競合状態を検出させられる。

まとめ:

本章はゴルーチン間のメモリ共有と競合の本質を整理する。共有メモリは複数実行が同一ボードを使う状況に喩えられ、Go
コンパイラは共有が疑われる値をヒープに逃がす。複数ゴルーチンが同じヒープ値へ同時書き込みすると競合状態が発生し、タイミング依存のハイゼンバグを生む。アトミックやクリティカルセクションの概念を踏まえつつ、スケジューラへの任意yieldでは解決しないため、適切な同期と通信で排除することが重要である。まず本当に共有メモリが最適か（チャネル/CSPの適用可否）を検討し、次に競合が起こる局面を特定する。Goは-raceオプションでデータ競合を検出でき、実行時に問題箇所の手掛かりを与える。

感想:

単純なメモリ共有で競合状態が容易に発生してしまうことが理解できる。また`-race`オプションについて具体的に学べるのが良い。

### 第4章 ミューテックスを使った同期

- クリティカルセクションを**ミューテックス**で保護することで、一度の1つのゴルーチンだけが共有資源にアクセスできるようになる。そうすることで競合状態を排除できる。
- ミューテックスの変形は**ロック**と呼ばれることもあり、並行プログラミングをサポートする全ての言語で使われている。
- ゴルーチンがミューテックスで保護されたコードのクリティカルセクションに到達すると、プログラムコード内の命令としてミューテックスをロックする、その後、ゴルーチンはクリティカルセクション内のコードの実行を開始し、終了するとミューテックスをアンロックする。
- ミューテックスがロックされている間は他のゴルーチンはクリティカルセクションにアクセスする事ができない。
- 既にロックされているミューテックスを他のゴルーチンがロックしようとすると、そのゴルーチンはそのミューテックスがアンロックするまで待機する。
- ロックの開放を待って2つ以上のゴルーチンが待機している場合には、ロックが介抱さっれると1つのゴルーチンだけが再開して、残りのゴルーチンは待たされる。
- ミューテックス（mutex）は相互排他（mutual exclusion）の略
- Goではミューテックスの機能は`sync`パッケージの`Mutex`型で提供されている。この方は`Lock()`と`Unlock()
`という2つの主要メソッドがあり、それぞれクリティカルセクションの開始と終了を示すのに使用できる。コード例（ch04/01_listing4.1_2）
- ミューテックスの機能はOSとハードウェアにより実現されている。
- 参考: [sync\.Mutexの仕組みを理解する \- Speaker Deck](https://speakerdeck.com/ffjlabo/sync-dot-mutexnoshi-zu-miwoli-jie-suru)
- ミューテックスによるロック範囲は適切に設定しないと、ゴルーチンの切り替え待ちの待ち時間が増え、全体として処理が遅くなってしまう。（ch04/02_listing4.3_4）
- ロックの範囲が適切になりように修正した例（ch04/03_listing4.5）
- ノンブロッキング・ミューテックス・ロック：ロックが可能かどうか確認し、ロックが不可能な場合には別の処理を行うこと。
  - Goには`TryLock()`関数があり、ロックを取得可能か確認出来る
  - `TryLock()`を使う1例は、特定のタスクの進行を妨げずにそのタスクの進行状況を確認するモニターゴルーチンがある。
  - サンプル（ch04/04_listing4.6）
- リーダー・ライダー・ミューテックスによる性能向上
  - リーダー・ライター・ミューテックス（readers-writer mutex）は、共有資源を更新する必要がある場合のみ並行処理を制限する、標準的なミューテックスの変形。
  - Goではリーダー・ライター・ミューテックスの実装として`sync.RWMutex`がある。通常の排他的ロックメソッドと排他的アンロックメソッドに加え、ミューテックスのリーダー側を使う為のメソッド、`RLock()`, 
    `RLocker()`, `RUnlock()`が用意されている。
  - リーダーミューテックスはクリティカルセクションを走査している間にデータ構造が変更されないようにするために必要。
  - ライターミューテックスは他からの書き込みは制限するが、読み込みは制限しない。
  - サンプル（ch04/06_listing4.10_11）

まとめ:

本節はミューテックスによる相互排他とその実践的運用を整理する。ミューテックスはクリティカルセクションを保護し、同時に1つのゴルーチンのみが共有資源へアクセスできるようにして競合状態を防ぐ。ロック中は他のゴルーチンは待機し、解放時に1つだけ再開される。Goではsync.MutexのLock/Unlockで利用するが、ロック範囲が広すぎると待ちが増え性能低下を招くため、適切な粒度に調整することが重要。TryLockにより取得不可時は別処理へ逃す非ブロッキング設計も可能で、監視や進捗確認などに有効。読み取り多数・書き込み少数のケースではsync.RWMutexを用い、RLock/RUnlockで並行読み取りを許可し、更新時のみ排他することでスループットを向上できる。用途に応じて排他戦略を選び、過剰なロックを避けて効率と安全性のバランスを取る。

感想:

ミューテックスの仕組みが理解できる。

### 第5章 条件変数とセマフォ

- **条件変数**: 条件編集はミューテックスの上に追加の機能を提供する。この機能はゴルーチンが特定の条件が発生するのを待つ状況で使用できる。
  - Goの条件変数の実装は`sync.Cond`型。Goで新たな条件変数を作るには`Locker`インテーフェイスをもったインスタンスが必要。コード例（ch05/03_listing5.3_4_5）
  - 参考: [sync package \- sync \- Go Packages](https://pkg.go.dev/sync#Cond)
  - ゴルーチンが`Signal()`もしくは`Broadcast()`を呼び出したときに`Wait()`で待機していないゴルーチンがいない場合にはそのシグナルは失われる。
  - `Signal()`は待機している中から1つのゴルーチンだけを呼び出し、`Broadcast()`は`Wait()`で待機している全てのゴルーチンを呼び出す。
  - **スターベーション**（starvation）とは、他の貪欲な実行によって資源が長時間もしくは無期限に利用できなくなり、共有資源へのアクセスを得られないない状況。（ch05/07_listing5.10）
  - スターベーションを起こさないようにするには、ゴルーチンをミューテックスで待たせる代わりに、条件変数を使って一時停止させる。
- **セマフォ**: セマフォ（semaphore）は、並行実行の許容数を指定できる点で、異なる種類の並行実行制御を提供する。
  - セマフォは共有資源へのアクセスを並行実行できるようにする固定数の許可を可能にする。全ての許可が使われると、1つの許可が再び開放されるまで、それ以上のアクセス要求は待機する必要がある。
  - ミューテックスは、排他的にアクセスできるゴルーチンが1つだけあることを保障するのに対して、セマフォは最大N個のゴルーチンがアクセスできることを保証する
  - 許可が1つしかないセマフォは、バイナリセマフォ（binary semaphore）と呼ばれる。
  - セマフォには準標準ライブラリがある [semaphore package \- golang\.org/x/sync/semaphore \- Go Packages](https://pkg.go.dev/golangorg/x/sync/semaphore)
  - 理解のための実装例（ch05/09_listing5.16､ch05/10_listing5.18）
  - 重み付けセマフォ（weighted semaphore）は、複数の許可を同時に獲得および開放するセマフォの一種（ch05/13_exam03）

まとめ:

条件変数とセマフォによる並行制御を整理する。条件変数（sync.Cond）はミューテックス上に待機・通知機構を提供し、特定条件が満たされるまでゴルーチンをWaitで休止、条件成立時にSignalで1つ、Broadcastで全員を再開させる。待機者がいない通知は失われる点に留意する。スターベーション対策として、ロックで待たせ続けるのではなく条件変数で眠らせるのが有効。セマフォは同時並行許容量を管理する原語的プリミティブで、ミューテックスが「同時1つ」に限定するのに対し、最大N個の並行アクセスを許す。許可が尽きれば開放まで待機する。許可数1のバイナリセマフォは相互排他に相当し、重み付きセマフォは複数許可を一括取得・解放できる。Goではx/sync/semaphoreが準標準として提供され、実装負荷を抑えつつ公平・効率的なリソース制御が行える。

感想:

条件変数とセマフォについて理解できる。

### 第6章 ウェイトグループとバリアを使った同期

- **ウェイトグループ**（weight group）と**バリア**（barrier）は、複数のゴルーチンといった実行の集まりに対して同期抽象化を行う機能のこと。
- ウェイトグループを使うと、並行タスクの集まりが完了するまでゴルーチンを待機させられる。
- Goの標準ライブラリには`sync`パッケージに`WaitGroup`型がある。この型には`Done()`, `Wait()`, `Add(delta int)`の3つのメソッドがある。
  - `Done()`: ウェイトグループのカウンタを1つ減らす。
  - `Wait()`: ウェイトグループのカウンタが0になるまで待つ
  - `Add(delta int)`: ウェイトグループのカウンタをdelta分増やす
  - 参考例（ch06/02_listing6.2）
  - 処理途中でウェイトグループのカウンタの加算が必要な例（ch06/05_listing6.5_6）
- バリアは、コード内の特定の場所でゴルーチンのグループを同期させる機能を提供する。
  - 実装によってはバリアを複数回再利用でき、再利用可能なバリアを循環式バリア（cycle barrier）と呼ぶ

まとめ:

選択箇所の要約（約400字）: 本節は複数ゴルーチンの同期抽象としてウェイトグループとバリアを解説する。ウェイトグループは並行タスク群の完了を待つ仕組みで、sync.WaitGroupのAddでタスク数を登録し、各タスク終了時にDoneで減算、呼び出し元はWaitでカウンタが0になるまで待機する。途中で追加発生するタスクにも動的に対応できる。一方、バリアはコード中の特定地点で参加ゴルーチン全員が到達するまで待たせ、揃った時に一斉に先へ進める同期機構である。実装次第では繰り返し再利用でき、循環式バリアとして段階的な処理をステップごとに同期させる用途に適する。用途としては、WGは「全部終わるまで待つ」集約・終了待ち、バリアは「各段の境界で揃える」工程同期に向く。

感想:

ウェイトグループとバリアの使用方法や使用すべき箇所が解った。

### 第7章 メッセージパッシングを使った通信

- メッセージパッシングを使うことの利点は、誤ったプログラミングによる競合状態を引き起こすリスクを大幅に低減できること。
- チャネルは共有メモリの内容を変更しないため、ゴルーチンはメモリ上で互いに干渉することはない。
- Goのチャネルは、2つ以上のゴルーチン感でメッセージを交換することを可能にする。
- チャネルを使用するには`make()`関数を使ってチャネルを作成する。ゴルーチンを作成するときに引数として作成したチャネルを渡す。
- メッセージの送信には`<-`演算子を使う。メッセージの受信は`msg = <-messages `の様にして行う。例（ch07/01_listing7.1_2）
- ゴルーチンがメッセージをチャネルに書き込む際に、そのメッセージを読み込むゴルーチンが存在しない場合、Go
  のチャネルはデフォルトでは**同期的である**ため、送信側ゴルーチンは、メッセージを読み込む準備ができた受信側ゴルーチンが現れるまで待機させられる。
- そして、読み込み側ゴルーチンが現れない場合、Goのランタイムがデッドロックのエラーにします。例（ch07/02_listing7.3）
- また、読み込み側のゴルーチンがあるのに、書き込み側ゴルーチンが現れない場合にもGoのランタイムがエラーにします。例（ch07/03_listing7.4）
- チャネルは同期的であるが、複数のメッセージを保存するように設定でき、バッファとして使用できる。
- チャネルはバッファの容量がある限りメッセージを保存し続ける。バッファがいっぱいになった場合は書き込み側のゴルーチンは書き込みを待たされる。
- バッファに保存されたメッセージは受信側には保存順に渡される（FIFO）。バッファにメッセージがある限り受信側は待たされない。また、バッファが空になった場合にはその時点で読み込みは待たされる。例（ch07/04_listing7.5_6）
- Goのチャネルはデフォルトでは双方向であるが、方向を設定することもできる。
- 関数の引数で`messages <-chan int`のように指定する事で、チャネルの方向を指定できる。この場合は受信のみを表す。一方`messages chan<- int`は送信のみを表す。（ch07/05_listing7.7）
- **センチネル値（sentinel value）**: 実行、プロセス、またはアルゴリズム終了を指示する、予め設定された値のこと。マルチスレッド、および分散システムではポイズンピル（poison 
  pill）メッセージと呼ばれることもある。
- Goではセンチネルメッセージを使う代わりに、コードで`close(channel)`組み込み関数を呼び出すことでチャネルをクローズできる。
- チャネルがクローズするとチャネルはその型のゼロ値を返す。（ch07/06_listing7.8_9）
- チャネルからメッセージを読み込む際には、メッセージの他にチャネルの状態を示すフラグが返される。チャネルがクローズした場合にはこのフラグが`false`になる（ch07/07_listing7.10）。
- チャネルが閉じられるまでメッセージを読み込む処理は`for .. range .. {}`で反復処理ができる（ch07/08_listing7.11）。
- チャネル経由でゴルーチンで動作させた関数の結果を受け取れる（ch07/09_listing7.12_13）。

まとめ:

Goのチャネルによるメッセージパッシングの基礎と終端処理を解説する。チャネルは共有メモリを直接変更せずにゴルーチン間で値を受け渡すため、競合状態のリスクを下げる。makeで生成し、<-演算子で送受信する。チャネルはデフォルトで同期的で、受信側がいなければ送信は待機し、対応する受信や送信が永遠に現れなければデッドロックとして検出される。バッファ付きにすれば容量の範囲で非同期化でき、FIFOで受信される。チャネルは双方向だが、関数引数で<-chan（受信専用）やchan<-（送信専用）として方向制限が可能。終了合図にはセンチネル値の代わりにcloseを用い、クローズ後の受信は型のゼロ値とfalseフラグを返す。for rangeでクローズまで読み続けられ、計算結果の回収にも有効である。

感想:

チャネルの使い方が理解できる。

### 第8章 チャネルをセレクト

- 複数チャネルからのセレクト
  - `select`文を使用することで、複数のチャネルの読み込み操作をまとめてグループ化し、何れかのチャネルにメッセージが棟立ちするまでゴルーチンを待機させられる。（ch08/01_listing8.1_2）
  - Goのこの`select`文は、プログラミング言語Newsqueakの`select`コマンド由来。参考: [Newsqueak \- Wikipedia](https://en.wikipedia.org/wiki/Newsqueak)
  - ノンブロッキング操作にチャネルを使うには、`select`文の`default:`を使用する。（ch08/02_listing8.3）
  - `default:`を使用することで、並行計算を実行できる。（ch08/03_listing8.4_5_6）
  - チャネルを使うことでタイムアウト処理を実現できる。（ch08/04_listing8.7）
  - チャネルにメッセージを書き込むときにも`select`文を使用できる。(ch08/05_listing8.8_9)
  - チャネルを`nil`にすることで`select`のケースを無効化する方法がある。この方法をnilチャネルパターンと呼ぶ。selectでチャネルがnilなケースがあった場合にはそのケースは単純に無視される。（ch08
    /07_listing8.11_12）
  - メッセージパッシングを使うか、メモリ共有を使用するかはそれぞれのオーバーヘッドを考慮し検討する必要がある。

まとめ:

本章はGoのselect文による複数チャネルの扱いを整理する。selectは複数の受信（および送信）操作を同時に待ち、いずれかが可能になるまでゴルーチンをブロックできる構文で、Newsqueak
由来の概念である。ノンブロッキング動作にはdefault節を用い、準備済みのケースがなければ直ちにdefaultに進むため、計算継続やポーリング、バックオフなどを実装できる。タイムアウトはtime.After等のチャネルとselectを組み合わせることで簡潔に表現可能。送信側の多重化もselectで行える。さらに、nilチャネルパターンを使うと、条件に応じて特定のケースを無効化でき、動的な経路切替やステート駆動の多路選択に有用。最後に、メッセージパッシングと共有メモリの選択は、同期・コピー・コンテキストスイッチなどのオーバーヘッドを勘案し、要件と性能目標に基づき判断することが重要と述べる。

感想:

複数のチャネルを使用する方法が解った。

### 第9章 チャネルを使ったプログラミング

- CSP
  - ミューテックスといった並行の基本操作で共有メモリを使うことは、SRCモデル（SRC model）と呼ばれることがある。
  - **CSP**（communicating sequential process）は並行システムを記述するのに使われる記述言語。メモリ共有を用いる代わりに、チャネルを介したメッセージパッシングに基づいている。
  - CSPの考え方は、Erlang, Occam, Go, ScalaのAkkaフレームワーク、Clojureのcore.async、その他多くのプログラミング言語やフレームワークの並行処理モデルに採用されている。
  - CSPでは、プロセスは値のコピーを交換することでお互いに通信する。通信は名前付きバッファ無しチャネルを介して行われる。ここでのプロセスはOSプロセスのことではなく、CSPプロセスは、それ自身の隔離された状態を持つ逐次実行のこと。
  - Go言語はゴルーチンとチャネルを使ってこのモデルを実装している。
  - CSPモデルとGoの実装の重要な違いは、Go
    ではチャネルがファーストクラスオブジェクトであると言うこと。ファーストクラスオブジェクトとは、チャネルを関数や、さらに他のチャネルに渡すことがで切ると言うこと。これによりプログラムの柔軟性が向上する。
- 一般的なチャネルパターンの再利用
  - Goでチャネルを使ってメッセージパッシングを行う場合、従うべきガイドラインが二つある。
    - チャネルに対してデータのコピーだけを渡す。
    - できるだけ、メッセージパッシングパターンとメモリ共有を混在させない。
  - quitチャネル
    - ゴルーチンにメッセージ処理の停止を指示する共通チャネルを持つパターン。
    - ゴルーチンはquitチャネルがクローズされたときに全てのメッセージ処理を中止する。
    - 例（ch09/01_listing9.1_2）
  - チャネルとゴルーチンによるパイプライン化
    - ゴルーチンをチャネルで接続して実行パイプラインを形成するパターン。
    - 例（ch09/04_listing9.7_8）
  - ファンインとファンアウト
    - Go言語のファンアウト（fan-out）並行パターンとは、複数のゴルーチンが同一チャネルより読み込むことを指す。
    - Go言語では、複数のチャネルからの内容を1つにマージする際に、ファンイン（fan-in）並行パターンが発生します。
    - 例（ch09/05_listing9.9_11）
  - クローズ時に結果を出力する
    - 例（ch09/06_listing9.12_13） 
  - 複数のゴルーチンへブロードキャストする
    - 例（ch09/07_listing9.16_17）
  - 条件成立後にチャネルをクローズする
    - 例（ch09/08_listing9.18_19）
- チャネルをファーストクラスオブジェクトとして活用
  - Goではチャネルを別のチャネルに渡すこともできる。
  - これにより線形パイプラインを使えるようになり、問題のサイズに拡張できる。
  - 例（ch09/09_listing9.20_21）

まとめ:

本章はCSPとGoにおけるチャネル活用を整理する。CSPは共有メモリではなくメッセージパッシングで並行性を実現する記述モデルで、Goはゴルーチンとチャネルでこれを実装する。Go
ではチャネルがファーストクラスであり、関数や他チャネルへ渡せるため設計の柔軟性が高い。ガイドラインとして、チャネルにはデータのコピーを渡し、メモリ共有との混在を避ける。代表パターンは、停止指示を共通チャネルで行うquitチャネル、段階処理をつなぐパイプライン、複数ゴルーチンで同一チャネルを読むファンアウトと、複数チャネルを1つに集約するファンイン、チャネルクローズ時に結果集約、複数ゴルーチンへのブロードキャスト、条件成立時のチャネルクローズなど。さらに、チャネル自体をメッセージとして渡すことで線形パイプラインを拡張し、問題規模に応じて構成をスケールできる点を強調する。

感想:

CSPとチャネルのパターンについて理解できる。

### 第10章 並行処理パターン

- プログラミングを個別の並行タスク分割するプロセスは分解（decomposition）と呼ばれる
  - タスク別にプログラムを分解する
    - タスク分解（task decomposition）はプログラム内の様々な処理を並行に実行できるか考え、並行実行できる処理に関してはタスクを分解する。タスク分解をした後は、各タスクについて、相互の依存性を確認する。
  - データ別にプログラムを分解する
    - データがプログラム内をどのように流れるかを考えることでプログラムも分解できる。たとえば、入力データを分割して複数の並列実行に渡せる。これは、データ分解（data 
      decomposition）と呼ばれ、「プログラム内のデータをどのように整理すれば、多くの作業を並列実行できるか」という質問を元に行われる。
    - 入力データ分解（input data decomposition）は、プログラムの入力データを分割し、複数の並行実行で処理する際に行われる。
    - 出力データ分解（output data decomposition）は、プログラムの出力データを使って作業を実行間で分散させる。
  - タスクの粒度（task granularity）とは、並行実行されるタスクの粒度のこと
    - 粒度分布の一方の端には、問題が多数の小さなタスクに分割された、細粒度（fine-grained）タスクがある。
    - もう一方の端には、問題が小数の大きなタスクに分割された。粗粒度（coarse-grained）タスクがある。
    - これら二つの中間に、最大のスピードアップを得られる最適な地点がある。
    - 最適なタスクの粒度は、主に解決しようとしている問題によって決定される。
      - タスクが小さな粒度で分解されると、個々のタスクはスピードアップされるが、個々のタスクの通信や同期によってスケーラビリティの制限を受け、結果的にほとんど影響ないか、あるいはマイナスの影響を与えることがある。
      - タスクが粗い粒度で分解されると、実行間の多くの通信や同期の必要性が減少する。しかし、小数の大きなタスクでは、スピードアップは小さくなり、実行間の負荷の不均衡につながる可能性がある。
      - シナリオに適したバランスを見つける必要があり、これは、モデリング、実験、テストによって行える。
      - 通信や同期をほとんど必要としない並行処理的な解決策は、一般的に、細かい粒度での解決方法が可能であり、大きなスピードアップが見込める。
- 一般的な並行処理パターンを認識する
  - ループレベル並行処理
    - データコレクションに対してあるタスクを実行する必要がある場合、並行処理を使って、そのコレクションの異なる部分に対して複数のタスクを同時に実行できる。通常はコレクションに対して、ループを使って一つ一つ逐次実行するが、このループレベル並行処理パターンでは、各反復タスクを並行タスクに変換して並行に実行できるようにする。（例: ch10/01_listing10.1, ch10/02_listing10.2）
    - ループキャリー依存性（loop-carried dependence）: ある反復のステップが、同じループ内の別の反復ステップに依存する場合。
      - 例（ch10/03_listing10.3）、ループキャリ依存性にゴルーチンを使用して対応した例（ch10/04_listing10.4）
  - フォーク／ジョイン・パターン
    - タスクを並行に実行するために複数の実行を作成する必要があり、その後、各タスクの結果を集約する必要がある場合、フォーク／ジョイン・パターンを使う。
      - タスクの実行を開始する（fork）と、その結果を待つ（join）という操作を繰り返す。
      - 例（ch10/05_listing10.5_6_7_8）
  - ワーカープールパターン
    - 場合によっては、どれだけの作業量になるのかわからない事がある。これへの解決策は、複数のワーカーと作業キューを用意すること。
    - ワーカープールパターンでは、予め作成された一定数のゴルーチンが作業の受け入れ準備をしている。
    - このパターンでは、ゴルーチンはアイドル状態か、タスク待ちの状態、あるいはタスク実行中のいずれかになる。
    - 作業は、共通の作業キューを介して、ワーカープールに渡される。すべてのワーカーが実行中の場合には、作業キューのサイズが大きくなる。作業キューが最大数に達した場合には、それ以上の作業の受入を停止できる。
    - ワーカープールの実装によっては、余分な負荷を処理するために、ゴルーチンの数を上限まで増やすことで、ワーカープールのサイズを拡大できる。
    - コード例（ch10/08_listing10.12）
  - パイプラインパターン
    - 各タスクが前のタスクが完了していることに完全に依存するタスクの集まりである場合、パイプラインパターンを適用する。
    - パイプラインパターンでは、異なるタスクのバッチごとにゴルーチンを割り当て、タスクごとに並行して作業を進めさせます。
    - このようにタスクごとに並行して作業したものを次のタスクに渡していくことで、後段のタスクが今自分が行ったタスクの結果を処理している間に、自分は新しいタスクを実行できます。
    - コード例（ch10/11_listing10.15_16）
    - パイプラインパターンで全体処理の効率化を図るには、一番時間がかかっているタスクを特定し、そのボトルネックとなっている処理を効率化する必要がある。

まとめ:

第10章は、処理を並行タスクに分解する指針と代表的パターンを解説する。分解はタスク分解とデータ分解があり、前者は並行化可能な処理を抽出し依存関係を確認、後者は入力や出力データの流れで作業を分散する。タスク粒度は細かすぎると同期・通信のオーバーヘッドで伸び悩み、粗すぎると負荷不均衡で伸びないため、問題に応じて実験し最適点を探る。パターンとして、コレクション処理を各反復で並行化するループレベル並行（ループキャリー依存に留意）、並行実行して結果を合流するフォーク／ジョイン、作業量不確定時にキューと一定数ワーカーで処理するワーカープール（必要に応じ拡張）、段階依存のタスクを流すパイプライン（ボトルネック特定と最適化が鍵）を挙げ、適材適所での適用を勧める。

感想:

並行処理のパターンについて理解できる。

### 第11章 デッドロックを回避

- デッドロック（deadlock）は、実行が互いに資源の開放を待つことで無限に待たされる場合に発生する。
- デッドロックは、並行実行が同時に複数の資源への排他的アクセスを獲得しようとしているときに、特定のへ移行プログラムで発生する望ましく無い副作用である。
- デッドロックを特定したり、デバッグするのは、とても難しい場合がある。競合状態と同様に、プログラムが長時間問題無く動作していても、突然、明らかな理由もなく実行が停止する事がある。
- デッドロックが発生する理由を理解することで、それを避けるためのプログラミング上の判断を下せるようになる。

- デッドロックの特定
  - 資源割り当てグラフ（RAG: resource allocation graph）は、さまざまな実行で利用される資源の関係性を示す。
  - 資源割り当てグラフは、OSでデッドロックの検出を含むさまざまな機能として使われている。
  - 資源割り当てグラフを描画することで、並行プロgラムにおけるデッドロックを視覚的に理解できる。
  - 1971年の論文「System Deadlocks」で、Coffmanらは、デッドロックが発生するには、次の4つの条件**すべて**が存在しなければならないことを示している。
    - 相互排他（mutual exclusion）: システム内の個々の資源は、1つの実行によって使われているか、使われていないかの何れかである。
    - 条件待ち（wait for condition）: 1つ以上の資源を保持する実行が、さらに資源を要求できる。
    - プリエンプションなし（no preemption）: 実行が保持している資源は取り除くことができない。資源を保持している実行のみが、その資源を開放できる。
    - 循環待機（circular wait）: 2つ以上の実行が感情に連鎖しており、各実行は次の実行で開放される資源を待って停止している。
  - 現実の世界でも、デッドロックの例は多数みられる。
  - デッドロックが発生するコード例（ch11/03_listing11.5）

- デッドロックに対処する
  - デッドロックを避けるには3つの取り組み方がある。
  - デッドロックの検出
  - デッドロックを避ける機構を使うこと
  - デッドロックのしなりをを避ける方法でへ移行プログラムを書くこと
  - そしてもうひとつの方法として「何もしない」がある。これはオーストリッチメソッド（ostrich method）と呼ばれる。

- デッドロックを検出する
  - デッドロックを検出できるようにすることで、プロセスを再起動できる担当者に再起動を促すアラートを伝える事ができるようになる。
  - さらに良い方法としては、デッドロックが発生するたびに通知を受け取って、再試行処理をするロジックをコードに組み込むこと。
  - デッドロックを完全に検出するには、すべてのゴルーチンと資源をノードとして表し、それをエッジで結んだ資源割り当てグラフをプログラムで作成するというもの
  - グラフ内の循環を検出する方法としては、深さ優先探索アルゴリズムを変更して、循環を探すようにする。
  - Goのランタイムは完全なデッドロック検出を提供しているわけではない。
  - Goのランタイムはデッドロックを検出すると、そのゴルーチンだけではなくプロセス全体を止めてしまう選択をしている。
- デッドロックを回避する
  - デッドロックが発生しないようにスケジュールすることで、デッドロックを回避できる。
  - このためのアルゴリズムにEdsger Dijkstraが開発した銀行家のアルゴリズム（banker's algorithm）がある。
  - このアルゴリズムは、次の情報がわかっている場合にのみ使用できる。
    - 各実行が要求できる各資源の最大数
    - 各実行が現在保持している資源
    - 各資源の利用可能数
  - 安全の定義: この情報を使ってシステムの状態が安全か、安全でないかを判断する。システムの状態は、資源の最大数を要求した場合でも、すべての実行が完了するようにスケジュールする方法がある場合のみ安全である。それ以外の場合は、システムの状態は安全でないと見なされる。
  - このアルゴリズムは、資源の要求を許可するかどうか決定するときに機能する。資源が割り当てられたあともシステムが安全な状態に維持される場合のみ、資源の要求を許可する。安全でないと判断される場合には、安全なん状態になるまで、資源の要求をしている実行は一時停止される。
- デッドロックを防ぐ
  - 並行実行で、排他的資源の集まりが事前にわかっている場合、順序づけによってデッドロックを防げる。
- チャネルでのデッドロック
  - デッドロックはミューテックスの使用に限定されないことを理解するのが重要。チャネルを使っても、実行が排他的な資源を保持し、他の資源を要求する場合、デッドロックが発生する可能性がある。
  - チャネルの容量は排他的な資源として考えられる。
  - チャネルを使い場合には、デッドロックを防ぐため、循環した街を避けるように注意する。
  - チャネルでは、別のゴルーチンを使って送受信したり、select文とチャネル操作を組み合わせたり、あるいは、循環したメッセージの流れを避けるようにプログラムを適切に設計したりすることで、循環した待ちを避けられる。

まとめ:

デッドロックは実行同士が互いの資源解放を待ち無限待機に陥る現象で、発見・デバッグは難しい。原因理解が回避判断に不可欠。特定には資源割り当てグラフ（RAG）が有効で、Coffmanの4条件（相互排他・条件待ち・プリエンプションなし・循環待機）が全て成り立つと発生する。対処は(1)検出（通知や自動再試行、グラフ循環検出など。ただしGoランタイムは完全検出ではなく、検出時はプロセスごと停止し得る）、(2)回避（銀行家のアルゴリズムで安全状態のみ許可。各実行の最大要求・保有・資源可用数が前提）、(3)防止（既知の排他資源に順序づけして取得順を統一）に大別される。チャネルでも容量が排他資源として働きうるため循環待ちが起こり得る。送受を別ゴルーチンに分ける、selectで経路を用意する、循環するメッセージ流を避ける設計でデッドロックを回避する。

感想:

本章はデッドロックの本質と対処法を体系的に押さえられたのが収穫でした。Coffmanの4条件で原因を整理し、検出・回避・防止の三層で向き合う視点が実践的。特に、順序づけでの防止や銀行家のアルゴリズムの「安全状態」概念は設計段階での指針として有効だと感じました。チャネルでも循環待ちが起こり得る点はGo特有の落とし穴で、selectや設計での回避発想を常に持ちたいと思います。

### 第12章 アトミック、スピンロック、フューテックス

- アトミック変数を使ったロックフリーの同期
  - アトミック変数は、中断されることなく特定の操作を実行可能にする。
  - Goでは`sync/atomic`パッケージにアトミック操作が含まれている。
  - コード例（ch12/01_listing12.1_2）
  - アトミック変数を使用する場合、性能ペナルティを支払うことになる。通常の方法で変数を更新する方が、アトミック操作で変数を変更するより遥かに高速。
  - コード例（ch12/02_listing12.3）
  - 記事中3倍程度遅いとあるが、M4のMac Book Proではそこまでの速度差はない。1.3倍程度の時間がかかっている。

- スピンロックでミューテックスを実装する
  - スピンロック（spin lock）とは、繰り返しロックを獲得しようとするループに入る種類のロック。
  - [スピンロックの実装例](https://github.com/cutajarj/ConcurrentProgrammingWithGo/blob/main/chapter12/listing12.9/spinlocks.go)

- フューテックスによるロック
  - フューテックス（futex）はfast userspace mutexの略。
  - 誤解を招くが、フューテックスはミューテックスとは異なるもの。
  - フューテックスは、ユーザー空間からアクセス可能な基本待ちのキュー操作のこと。特定のアドレスの実行を一時停止したり再開したりする機能を提供する。
  - Goではフューテックスのシステムコールにアクセスできない。

- Goのミューテックス実装
  - Go言語での`sync.Mutex`の実装ではセマフォが使われている。
  - このセマフォの実装は、ロックが利用できない場合にゴルーチンを待機キューに入れる役割を果たす。
  - このセマフォはGoの内部実装の一部であり、直接アクセスはできない。
  - <https://github.com/golang/go/blob/master/src/runtime/sema.go> ここで実装は確認出来る

まとめ:

Goにおける低レベル同期原語の概観である。まずアトミック変数は中断不能な原子的操作を提供し、sync/atomicで実装できるが、通常の変数更新より遅く、測定では約1.3倍のオーバーヘッドが見られた。次にスピンロックはロック取得を忙待ちで繰り返す方式で、軽量だが競合時にCPUを消費しやすい。フューテックスは「ユーザー空間での待ちキュー」操作を指し、特定アドレスに紐づく待機・再開を可能にするが、Goから直接システムコールは利用できない。最後にGoのsync.Mutexは内部でセマフォを用い、取得不可時にゴルーチンを待機キューへ入れる実装となっている（runtime/sema.go）。総じて、性能・公平性・消費資源のトレードオフを理解し、用途に応じて原語を選択することが要点である。

感想:

アトミックやスピンロック、フューテックス、Mutex内部実装を俯瞰でき、有効性と制約の整理に役立った。特にsync/atomicの実測で理論との差異（約1.3倍の遅さ）を確認でき、性能評価の重要性を再認識。スピンロックの忙待ちのコストや、Goで直接使えないフューテックスの位置づけも理解が深まった。最終的に、用途に応じた原語選択とトレードオフの見極めが実践上の肝だと感じた。

### 全体の感想

本書は、Goの並行処理を「概念→実装→パターン→落とし穴」の流れで系統立てて掴める良書という印象でした。序盤はCSP思想やアムダール／グスタフソンの法則を押さえ、なぜGoがゴルーチンとチャネルを中核に据えるのかを腹落ちさせます。続く章で、OS/ユーザースレッドとM:Nスケジューリング、LRQ/GRQやワークスティーリングまで踏み込むため、ブラックボックスだった実行時の挙動が見える化され、設計判断の根拠が増えます。共有メモリの競合・ハイゼンバグから出発して、Mutex/RWMutex、Cond、セマフォ、WaitGroup/バリアと段階的に同期原語を学び、目的別にどう使い分けるべきかが明瞭です。チャネルとselectは、クローズ、方向制限、バッファ、タイムアウト、nilチャネルなど実務で必要な作法が網羅され、CSPパターン（パイプライン、ファンイン/アウト、quitチャネル、ブロードキャスト）も具体的です。さらに、分解戦略やワーカープール、フォーク/ジョイン、パイプライン最適化といったパフォーマンス志向の視点が実装に橋を架けます。デッドロックはCoffmanの4条件、RAG、銀行家のアルゴリズムまで扱い、チャネルでも循環待ちが起こるという“Goならでは”の注意点を明示。終盤のアトミックやスピンロック、Mutex内部のセマフォ実装への言及は、低レイヤの理解を補強し、いたずらな最適化や誤用を戒めます。総じて、基礎理論からランタイム、言語機能、設計パターン、アンチパターンまで縦断的に学べるため、Goで並行処理を本気で身につけたい読者に強く勧められる内容です。実装時の指針が増え、トレードオフを自分で評価する力が確実に養われます。
